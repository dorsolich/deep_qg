{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYSIS OF THE DIFFERENCES BETWEEN QUESTIONS USEFUL FOR LEARNING AND NOT USEFUL FOR LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DeboraOrsolich\\miniconda3\\envs\\ques_gen_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import notebook_hook\n",
    "import logging, sys\n",
    "logging.disable(sys.maxsize)\n",
    "import pathlib\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from qg.results_analysis.objects.POSAnalysis import POS_analysis_object\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory: C:\\Users\\DeboraOrsolich\\Development\\question_generation_models\\deep_qg\\qg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fraction are very confusing to me i did n't re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i may be jumping the gun here , but has the te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is it because the position function can not be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at 2:04 he said he uses gesso sometimes , what...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when our hypothesis is herbs do nothing then w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  fraction are very confusing to me i did n't re...       0\n",
       "1  i may be jumping the gun here , but has the te...       1\n",
       "2  is it because the position function can not be...       0\n",
       "3  at 2:04 he said he uses gesso sometimes , what...       0\n",
       "4  when our hypothesis is herbs do nothing then w...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading learning Q data...\n",
    "ROOT_DIR = pathlib.Path().resolve().parents[0]\n",
    "print(f\"Root directory: {ROOT_DIR}\")\n",
    "\n",
    "with open(ROOT_DIR/\"LearningQ_data\"/\"cls_balanced_dataset.json\") as f:\n",
    "    learningq = json.load(f)\n",
    "\n",
    "df = pd.DataFrame.from_dict(learningq[\"test\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480 480\n"
     ]
    }
   ],
   "source": [
    "# preparing the data for the analysis...\n",
    "useful = df[df[\"labels\"]==1]\n",
    "not_useful = df[df[\"labels\"]==0]\n",
    "\n",
    "sets = [useful, not_useful]\n",
    "sets_name = [\"useful\", \"not_useful\"]\n",
    "print(len(sets[0]), len(sets[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there statistically significant differences in the number of words in the questions of each group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, there are statistically significant differences in the length of the questions between the two groups\n",
      "   P-value = 1.0373387011520134e-10\n",
      "   Average length of useful questions 17.016666666666666 tokens\n",
      "   Average length of not_useful questions 13.022916666666667 tokens\n"
     ]
    }
   ],
   "source": [
    "def count_tokens(text):\n",
    "    return len(text.split())\n",
    "\n",
    "word_counts = {}\n",
    "for set, name in zip(sets, sets_name):\n",
    "    n_words = []\n",
    "    for question in set[\"text\"].values:\n",
    "        n_words.append(count_tokens(question))\n",
    "\n",
    "    word_counts[name] = n_words\n",
    "\n",
    "fvalue, pvalue = stats.f_oneway(word_counts[\"useful\"], word_counts[\"not_useful\"])\n",
    "\n",
    "if pvalue < 0.05:\n",
    "    print(\"Yes, there are statistically significant differences in the length of the questions between the two groups\")\n",
    "\n",
    "else:\n",
    "    print(\"No, there are not statistically significant differences in the length of the questions between the two groups\")\n",
    "\n",
    "print(f\"   P-value = {pvalue}\")\n",
    "print(f\"   Average length of useful questions {np.mean(word_counts['useful'])} tokens\")\n",
    "print(f\"   Average length of not_useful questions {np.mean(word_counts['not_useful'])} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there statistically significant differences in the number of concepts in the questions of each group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480/480 [00:00<00:00, 79563.15it/s]\n",
      "100%|██████████| 480/480 [00:00<00:00, 96379.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, there are statistically significant differences in the number of concepts in each question between the two groups\n",
      "   P-value = 1.3678269253697558e-19\n",
      "   Average number of concepts in useful questions: 3.0541666666666667\n",
      "   Average number of concepts in not useful questions: 1.9333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "concepts_count = {}\n",
    "strings_groups = {}\n",
    "for set, name in zip(sets, sets_name):\n",
    "    pos_analysis = POS_analysis_object()\n",
    "    questions_pipeline = pos_analysis.nlp_pipeline(set[\"text\"].values)\n",
    "\n",
    "    strings = []\n",
    "    lemmas = []\n",
    "    for question in tqdm(questions_pipeline):\n",
    "        pos_analysis.extract_pos_concepts(question, split_in_documents=True)\n",
    "        strings.append(pos_analysis.all_concepts_string)\n",
    "        lemmas.append(pos_analysis.all_concepts_lemma)\n",
    "    \n",
    "\n",
    "    concepts_count[name] = [len(x) for x in strings]\n",
    "    strings_groups[name] = strings\n",
    "\n",
    "fvalue, pvalue = stats.ttest_ind(concepts_count[\"useful\"], concepts_count[\"not_useful\"])\n",
    "\n",
    "if pvalue < 0.05:\n",
    "    print(\"Yes, there are statistically significant differences in the number of concepts in each question between the two groups\")\n",
    "\n",
    "else:\n",
    "    print(\"No, there are not statistically significant differences in the number of concepts in each question between the two groups\")\n",
    "\n",
    "print(f\"   P-value = {pvalue}\")\n",
    "print(f\"   Average number of concepts in useful questions: {np.mean(concepts_count['useful'])}\")\n",
    "print(f\"   Average number of concepts in not useful questions: {np.mean(concepts_count['not_useful'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there statistically significant differences in the proportion of concepts per words in each question between both groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480/480 [00:00<00:00, 96126.14it/s]\n",
      "100%|██████████| 480/480 [00:00<00:00, 121069.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, there are statistically significant differences in the proportion of concepts per word in each question between the two groups\n",
      "   P-value = 8.11429827881051e-14\n",
      "   Average proportion of concepts per words in useful questions: 0.1833690717818408\n",
      "   Average proportion of concepts per words in not_useful questions: 0.14494073167877858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "concepts_proportions = {}\n",
    "for set, name in zip(sets, sets_name):\n",
    "    pos_analysis = POS_analysis_object()\n",
    "    questions_pipeline = pos_analysis.nlp_pipeline(set[\"text\"].values)\n",
    "\n",
    "    proportions = []\n",
    "    for question in tqdm(questions_pipeline):\n",
    "        pos_analysis.extract_pos_concepts(question, split_in_documents=True)\n",
    "        proportions.append(len(pos_analysis.all_concepts_string)/len(question))\n",
    "\n",
    "    concepts_proportions[name] = proportions\n",
    "\n",
    "fvalue, pvalue = stats.ttest_ind(concepts_proportions[\"useful\"], concepts_proportions[\"not_useful\"])\n",
    "\n",
    "if pvalue < 0.05:\n",
    "    print(\"Yes, there are statistically significant differences in the proportion of concepts per word in each question between the two groups\")\n",
    "\n",
    "else:\n",
    "    print(\"No, there are not statistically significant differences HAVE NOT been found in the proportion of concepts per word in each question between the two groups\")\n",
    "\n",
    "print(f\"   P-value = {pvalue}\")\n",
    "print(f\"   Average proportion of concepts per words in useful questions: {np.mean(concepts_proportions['useful'])}\")\n",
    "print(f\"   Average proportion of concepts per words in not_useful questions: {np.mean(concepts_proportions['not_useful'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the most frequent concepts in each group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_strings_useful = [concept for question in strings_groups[\"useful\"] for concept in question ]\n",
    "all_strings_not_useful = [concept for question in strings_groups[\"not_useful\"] for concept in question ]\n",
    "\n",
    "cnt = Counter()\n",
    "cnt_useful = Counter(all_strings_useful)\n",
    "cnt_not_useful = Counter(all_strings_not_useful)\n",
    "\n",
    "cnt_useful = sorted(cnt_useful.items(), key=lambda item: item[1])\n",
    "cnt_not_useful = sorted(cnt_not_useful.items(), key=lambda item: item[1])\n",
    "\n",
    "cnt_useful.reverse()\n",
    "cnt_not_useful.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 MORE FREQUENT CONCEPTS IN USEFUL QUESTIONS\n",
      "   Concept:   frequency\n",
      "  0.   number:     21\n",
      "  1.   asthma:     18\n",
      "  2.   gcf:     17\n",
      "  3.   sal:     17\n",
      "  4.   function:     15\n",
      "  5.   sequence:     14\n",
      "  6.   numbers:     13\n",
      "  7.   difference:     12\n",
      "  8.   force:     11\n",
      "  9.   equation:     11\n",
      "\n",
      "10 MORE FREQUENT CONCEPTS IN NOT USEFUL QUESTIONS\n",
      "   Concept:   frequency\n",
      "  0.   video:     33\n",
      "  1.   number:     14\n",
      "  2.   sal:     12\n",
      "  3.   answer:     11\n",
      "  4.   question:     9\n",
      "  5.   numbers:     9\n",
      "  6.   time:     9\n",
      "  7.   month:     7\n",
      "  8.   way:     7\n",
      "  9.   problem:     6\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "\n",
    "print(f\"{n} MORE FREQUENT CONCEPTS IN USEFUL QUESTIONS\")\n",
    "print(f\"   Concept:   frequency\")\n",
    "for i in range(n):\n",
    "    concept = cnt_useful[i][0]\n",
    "    count = cnt_useful[i][1]\n",
    "    print(f\"  {i}.   {concept}:     {count}\")\n",
    "\n",
    "print()\n",
    "print(f\"{n} MORE FREQUENT CONCEPTS IN NOT USEFUL QUESTIONS\")\n",
    "print(f\"   Concept:   frequency\")\n",
    "for i in range(n):\n",
    "    concept = cnt_not_useful[i][0]\n",
    "    count = cnt_not_useful[i][1]\n",
    "    print(f\"  {i}.   {concept}:     {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there statistically significant differences in the number of verbs in each question between both groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480/480 [00:00<00:00, 119851.53it/s]\n",
      "100%|██████████| 480/480 [00:00<00:00, 59409.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, there are statistically significant differences in the number of VERBS in each question between the two groups\n",
      "   P-value = 0.009772871825290252\n",
      "   Average number of verbs in useful questions: 1.2291666666666667 verbs\n",
      "   Average number of verbs in not useful questions: 1.0416666666666667 verbs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "verbs_count = {}\n",
    "verbs_groups = {}\n",
    "for set, name in zip(sets, sets_name):\n",
    "    pos_analysis = POS_analysis_object()\n",
    "    questions_pipeline = pos_analysis.nlp_pipeline(set[\"text\"].values)\n",
    "\n",
    "    verbs = []\n",
    "    for question in tqdm(questions_pipeline):\n",
    "        pos_analysis.extract_pos_concepts(question, split_in_documents=True, filter_pos=[\"VERB\"])\n",
    "        verbs.append(pos_analysis.all_concepts_string)\n",
    "\n",
    "    verbs_count[name] = [len(x) for x in verbs]\n",
    "    verbs_groups[name] = verbs\n",
    "\n",
    "fvalue, pvalue = stats.ttest_ind(verbs_count[\"useful\"], verbs_count[\"not_useful\"])\n",
    "\n",
    "if pvalue < 0.05:\n",
    "    print(\"Yes, there are statistically significant differences in the number of VERBS in each question between the two groups\")\n",
    "\n",
    "else:\n",
    "    print(\"No, there are not statistically significant differences in the number of VERBS in each question between the two groups\")\n",
    "\n",
    "print(f\"   P-value = {pvalue}\")\n",
    "print(f\"   Average number of verbs in useful questions: {np.mean(verbs_count['useful'])} verbs\")\n",
    "print(f\"   Average number of verbs in not useful questions: {np.mean(verbs_count['not_useful'])} verbs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there statistically significant differences in the proportion of verbs per words in each question between both groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480/480 [00:00<00:00, 120159.11it/s]\n",
      "100%|██████████| 480/480 [00:00<00:00, 96025.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, there are statistically significant differences in the proportion of VERBS per words in each question between the two groups\n",
      "   P-value = 0.038727064317922937\n",
      "   Average proportion of verbs per words in useful questions: 0.07043259976922919 verbs\n",
      "   Average proportion of verbs per words in not useful questions: 0.07963727977227195 verbs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "verbs_proportions = {}\n",
    "for set, name in zip(sets, sets_name):\n",
    "    pos_analysis = POS_analysis_object()\n",
    "    questions_pipeline = pos_analysis.nlp_pipeline(set[\"text\"].values)\n",
    "\n",
    "    proportions = []\n",
    "    for question in tqdm(questions_pipeline):\n",
    "        pos_analysis.extract_pos_concepts(question, split_in_documents=True, filter_pos=[\"VERB\"])\n",
    "        proportions.append(len(pos_analysis.all_concepts_string)/len(question))\n",
    "\n",
    "    verbs_proportions[name] = proportions\n",
    "\n",
    "fvalue, pvalue = stats.ttest_ind(verbs_proportions[\"useful\"], verbs_proportions[\"not_useful\"])\n",
    "\n",
    "if pvalue < 0.05:\n",
    "    print(\"Yes, there are statistically significant differences in the proportion of VERBS per words in each question between the two groups\")\n",
    "\n",
    "else:\n",
    "    print(\"No, there are not Statistically significant differences in the proportion of VERBS per words in each question between the two groups\")\n",
    "\n",
    "print(f\"   P-value = {pvalue}\")\n",
    "print(f\"   Average proportion of verbs per words in useful questions: {np.mean(verbs_proportions['useful'])} verbs\")\n",
    "print(f\"   Average proportion of verbs per words in not useful questions: {np.mean(verbs_proportions['not_useful'])} verbs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_verbs_useful = [verb for question in verbs_groups[\"useful\"] for verb in question ]\n",
    "all_verbs_not_useful = [verb for question in verbs_groups[\"not_useful\"] for verb in question ]\n",
    "\n",
    "cnt = Counter()\n",
    "cnt_useful = Counter(all_verbs_useful)\n",
    "cnt_not_useful = Counter(all_verbs_not_useful)\n",
    "\n",
    "cnt_useful = sorted(cnt_useful.items(), key=lambda item: item[1])\n",
    "cnt_not_useful = sorted(cnt_not_useful.items(), key=lambda item: item[1])\n",
    "\n",
    "cnt_useful.reverse()\n",
    "cnt_not_useful.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 MORE FREQUENT VERBS IN USEFUL QUESTIONS\n",
      "   Verb:   frequency      Proportion\n",
      "  0.   know:     20      0.03389830508474576\n",
      "  1.   find:     19      0.03220338983050847\n",
      "  2.   use:     18      0.030508474576271188\n",
      "  3.   mean:     12      0.020338983050847456\n",
      "  4.   write:     11      0.01864406779661017\n",
      "  5.   divide:     9      0.015254237288135594\n",
      "  6.   need:     9      0.015254237288135594\n",
      "  7.   says:     8      0.013559322033898305\n",
      "  8.   add:     8      0.013559322033898305\n",
      "  9.   multiply:     8      0.013559322033898305\n",
      "\n",
      "10 MORE FREQUENT VERBS IN NOT USEFUL QUESTIONS\n",
      "   Verb:   frequency      Proportion\n",
      "  0.   know:     23      0.046\n",
      "  1.   use:     21      0.042\n",
      "  2.   mean:     17      0.034\n",
      "  3.   help:     12      0.024\n",
      "  4.   solve:     12      0.024\n",
      "  5.   explain:     10      0.02\n",
      "  6.   find:     10      0.02\n",
      "  7.   understand:     10      0.02\n",
      "  8.   come:     9      0.018\n",
      "  9.   need:     8      0.016\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "\n",
    "print(f\"{n} MORE FREQUENT VERBS IN USEFUL QUESTIONS\")\n",
    "print(f\"   Verb:   frequency      Proportion\")\n",
    "for i in range(n):\n",
    "    verb = cnt_useful[i][0]\n",
    "    count = cnt_useful[i][1]\n",
    "    prop = cnt_useful[i][1] / len(all_verbs_useful)\n",
    "    print(f\"  {i}.   {verb}:     {count}      {prop}\")\n",
    "\n",
    "print()\n",
    "print(f\"{n} MORE FREQUENT VERBS IN NOT USEFUL QUESTIONS\")\n",
    "print(f\"   Verb:   frequency      Proportion\")\n",
    "for i in range(n):\n",
    "    verb = cnt_not_useful[i][0]\n",
    "    count = cnt_not_useful[i][1]\n",
    "    prop = cnt_not_useful[i][1] / len(all_verbs_not_useful)\n",
    "    print(f\"  {i}.   {verb}:     {count}      {prop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480/480 [00:00<00:00, 478437.72it/s]\n",
      "100%|██████████| 480/480 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "first_words = {}\n",
    "for set, name in zip(sets, sets_name):\n",
    "    pos_analysis = POS_analysis_object()\n",
    "    questions_pipeline = pos_analysis.nlp_pipeline(set[\"text\"].values)\n",
    "\n",
    "    first_word = []\n",
    "    for question in tqdm(questions_pipeline):\n",
    "        first_word.append(str(question[0]))\n",
    "    first_words[name] = first_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter()\n",
    "cnt_useful = Counter(first_words[\"useful\"])\n",
    "cnt_not_useful = Counter(first_words[\"not_useful\"])\n",
    "\n",
    "cnt_useful = sorted(cnt_useful.items(), key=lambda item: item[1])\n",
    "cnt_not_useful = sorted(cnt_not_useful.items(), key=lambda item: item[1])\n",
    "\n",
    "cnt_useful.reverse()\n",
    "cnt_not_useful.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 MORE FREQUENT FIRST WORDS IN USEFUL QUESTIONS\n",
      "   Init word:   frequency      Proportion\n",
      "  0.   what:     69      0.14375\n",
      "  1.   how:     69      0.14375\n",
      "  2.   why:     37      0.07708333333333334\n",
      "  3.   is:     37      0.07708333333333334\n",
      "  4.   at:     27      0.05625\n",
      "  5.   so:     24      0.05\n",
      "  6.   if:     21      0.04375\n",
      "  7.   does:     17      0.035416666666666666\n",
      "  8.   can:     16      0.03333333333333333\n",
      "  9.   i:     15      0.03125\n",
      "  10.   are:     13      0.027083333333333334\n",
      "  11.   would:     13      0.027083333333333334\n",
      "  12.   in:     12      0.025\n",
      "  13.   when:     11      0.022916666666666665\n",
      "  14.   for:     8      0.016666666666666666\n",
      "  15.   do:     7      0.014583333333333334\n",
      "  16.   should:     5      0.010416666666666666\n",
      "  17.   the:     4      0.008333333333333333\n",
      "  18.   could:     4      0.008333333333333333\n",
      "  19.   but:     4      0.008333333333333333\n",
      "\n",
      "20 MORE FREQUENT FIRST WORDS IN NOT USEFUL QUESTIONS\n",
      "   Init word:   frequency      Proportion\n",
      "  0.   what:     60      0.125\n",
      "  1.   is:     58      0.12083333333333333\n",
      "  2.   how:     36      0.075\n",
      "  3.   why:     32      0.06666666666666667\n",
      "  4.   can:     29      0.06041666666666667\n",
      "  5.   i:     23      0.04791666666666667\n",
      "  6.   does:     16      0.03333333333333333\n",
      "  7.   at:     15      0.03125\n",
      "  8.   if:     14      0.029166666666666667\n",
      "  9.   would:     12      0.025\n",
      "  10.   are:     11      0.022916666666666665\n",
      "  11.   so:     10      0.020833333333333332\n",
      "  12.   do:     9      0.01875\n",
      "  13.   and:     8      0.016666666666666666\n",
      "  14.   but:     8      0.016666666666666666\n",
      "  15.   where:     8      0.016666666666666666\n",
      "  16.   or:     8      0.016666666666666666\n",
      "  17.   in:     6      0.0125\n",
      "  18.   could:     5      0.010416666666666666\n",
      "  19.   which:     5      0.010416666666666666\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "\n",
    "print(f\"{n} MORE FREQUENT FIRST WORDS IN USEFUL QUESTIONS\")\n",
    "print(f\"   Init word:   frequency      Proportion\")\n",
    "for i in range(n):\n",
    "    verb = cnt_useful[i][0]\n",
    "    count = cnt_useful[i][1]\n",
    "    prop = cnt_useful[i][1] / len(first_words[\"useful\"])\n",
    "    print(f\"  {i}.   {verb}:     {count}      {prop}\")\n",
    "\n",
    "print()\n",
    "print(f\"{n} MORE FREQUENT FIRST WORDS IN NOT USEFUL QUESTIONS\")\n",
    "print(f\"   Init word:   frequency      Proportion\")\n",
    "for i in range(n):\n",
    "    verb = cnt_not_useful[i][0]\n",
    "    count = cnt_not_useful[i][1]\n",
    "    prop = cnt_not_useful[i][1] / len(first_words[\"not_useful\"])\n",
    "    print(f\"  {i}.   {verb}:     {count}      {prop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ques_gen_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc601a73fdd21029cabb389f5777df311758dfa951f719b3a4a78b5169f7a217"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
